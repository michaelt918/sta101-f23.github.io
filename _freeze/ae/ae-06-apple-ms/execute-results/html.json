{
  "hash": "d9914624e41cb7ca89d7ba6c0f97d192",
  "result": {
    "markdown": "---\ntitle: \"Apple and Microsoft stock prices\"\ncategories: \n  - Application exercise\neditor: visual\n---\n\n\nToday we'll explore the question \"How do stock prices of Apple and Microsoft relate to each other?\"\n\n# Goals\n\n-   Understand the grammar of linear modeling, including $y$, $x$, $b$, $e$ fitted estimates and residuals\n\n-   Add linear regression plots to your 2D graphs\n\n-   Write a simple linear regression model mathematically\n\n-   Fit the model to data in R in a `tidy` way\n\n# Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\n```\n:::\n\n\n# Data\n\nThe data for this application exercise was originally gathered using the [**tidyquant**](https://business-science.github.io/tidyquant/) R package. It features Apple and Microsoft stock prices from January 1st 2020 to December 31st 2021.\n\nFirst, let's load the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstocks <- read_csv(\"data/stocks.csv\")\n```\n:::\n\n\n# Models and residuals\n\n## Exercise 1\n\nAt first, you might be tempted to minimize $\\sum_i e_i$, but this is problematic. Why? Can you come up with a better solution (other than the one listed below)?\n\n[answer here]\n\nIn practice, we minimize the **sum of squared residuals**: \n\n$$\n\\sum_i e_i^2\n$$\n\nNote, this is the same as \n\n$$\n\\sum_i (y_i - \\hat{y})^2\n$$\n\n## Exercise 2\n\nCheck out an interactive visualization of \"least squares regression\" [here](https://seeing-theory.brown.edu/regression-analysis/index.html#section1). Click on `I` and drag the points around to get started. Describe what you see.\n\n*Add response here*\n\n## Exercise 3\n\nHow far off is your model (from Exercise 1) from the actual observed data on January 11 2020? The observed value is  MSFT: \\$164.35 and AAPL: \\$78.4. Compute the single square residual using your **fitted model** from Exercise 1.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# code here\n```\n:::\n\n\n# Plotting the OLS regression line\n\nPlotting the OLS regression line, that is, the line that minimizes the sum of square residuals takes one new geom. Simply add \n\n```\ngeom_smooth(method = \"lm\", se = FALSE)\n```\n\nto your plot.\n\n`method = \"lm\"` says to draw a line according to a \"linear model\" and `se = FALSE` turns off standard error bars. You can try without these options for comparison.\n\nOptionally, you can change the color of the line, e.g.\n\n```\ngeom_smooth(method = '\"lm\", se = FALSE, color = \"red\")\n```\n\n## Exercise 4\n\nCopy your code from Exercise 1 below. Add `geom_smooth()` as described above with `color = \"steelblue\"` to see how close your line is.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# code here\n```\n:::\n\n\n# Finding $\\hat{\\beta}$\n\nTo **fit the model** in R, i.e. to \"find $\\hat{\\beta}$\", use the code below as a template:\n\n```\nmodel_fit <- linear_reg() |>\n  fit(y ~ x, data = dataframe)\n```\n\n- `linear_reg` tells `R` we will perform linear regression\n- `fit` defines the outcome $y$, predictor $x$ and the data set\n\nRunning the code above, but replacing the arguments of the `fit` command appropriately will create a new object called `model_fit` that stores all information about your fitted model.\n\nTo access the information, you can run, e.g.\n\n```\ntidy(model_fit)\n```\n\nLet's try it out.\n\n## Exercise 5\n\nFind the OLS fitted linear model $y = \\hat{\\beta_0} + \\hat{\\beta_1} x$ for January 2020, where $x$ is Microsoft's opening price and $y$ is Apple's opening price. Print your results to the screen\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# code here\n```\n:::\n\n\n\n## Exercise 6\n\nRe-write the fitted equation replacing $\\beta_0$ and $\\beta_1$ with the OLS fitted values.\n\n$$\n\\text{[your equation here]}\n$$",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}